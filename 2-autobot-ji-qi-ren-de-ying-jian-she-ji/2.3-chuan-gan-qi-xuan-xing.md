# 2.3 传感器选型

## 2.3.1 惯性测量单元

惯性测量单元，即IMU，是机器人获取当前位姿和运动状态的传感器。惯性测量数据与双目视觉图像进行紧耦合优化，能显著提高系统的鲁棒性\[5]；与激光雷达点云数据的融合能有效提高对物体的检测能力\[6]。

本人在武术擂台机器人的设计中，发现短时间内使用六轴传感器能保持一定精度，当机器人长时间运行时，其Z轴误差较大。这是因为在六轴传感器中，Z轴角度是由角速度积分计算得到的，存在累计误差，当机器人运行时间过长时，累计误差会产生一定影响。九轴传感器相较于六轴传感器多了三轴的磁场数据，其角度信息与磁强计的磁场数据进行融合，能保持一定的稳定性。但九轴传感器容易受到外部磁场影响，除地理位置的特殊磁场，机器人的电机、电磁手指、扬声器等都会对九轴传感器产生影响，所以在机器人的结构设计时要注意减小机器人其他系统的磁场干扰。

本机器人的惯性测量单元选取维特智能JY901。JY901内置MPU9250芯片，能读取三轴加速度、三轴角速度、三轴磁场等原始数据，在JY901模块内还内置一个Cortex-M0内核处理器，使用高动态卡尔曼滤波融合算法对MPU9250的原始数据进行预处理，可通过串口或IIC输出更加平滑稳定的数据。JY901还可链接符合NMEA-0183的GPS模块，组成惯性组合导航单元。由于GPS卫星信号穿透能力差，在室内环境中不适用，所以本机器人的设计过程不包含GPS数据的解算，但在电路设计时为GPS数据的读取留出了接口，便于机器人功能的扩展。

## 2.3.2 激光雷达

激光雷达是机器人建图与导航实现的核心传感器，2D的激光雷达能够获取统一平面内的景深信息，得到二维点云图。本人在大学四年的学习过程中共使用过三款激光雷达，分别为：思岚A2、思岚S1和杉川Delta 3A，现将其参数列举如下：

|       | 思岚A2                                                                | 思岚S1                           | 杉川Delta 3A         |
| ----- | ------------------------------------------------------------------- | ------------------------------ | ------------------ |
| 测量半径  | 0.2m\~16m                                                           | <p>白色物体：40m</p><p>黑色物体：10m</p> | 0.25m\~16m（反射率80%） |
| 采样频率  | 8000Hz                                                              | 9200Hz                         | 8000Hz             |
| 扫描频率  | 5Hz\~15Hz可调                                                         | 8\~15Hz可调                      | 5\~15Hz可调          |
| 角度分辨率 | 0.9°                                                                | 0.313°\~0.587°（取决于扫描频率）        | 0.25°\~0.7°        |
| 测距分辨率 | <p>≤实际距离的 1%（测距≤12m)</p><p>≤实际距离的 2%（测距12m～16m)</p>                 | 3cm                            | 1mm                |
| 测量精度  | <p>实际距离的 1%（≤3 m）</p><p>实际距离的 2%（3-5 m）</p><p>实际距离的 2.5%（5-16m）</p> | ±5cm                           | <1% (16m)          |

以上激光雷达参数上思岚S1要更胜一筹，在实际使用时思岚S1的综合表现也要比其余两个好一点，但本机器人的设计目的为室内环境下的巡检与协作机器人，在本机器人的实际使用时无法发挥出该款激光雷达的突出特点，如40m测量半径，较高测量精度等。所以综合考虑价格与实用性能选择杉川雷达的Delta-3A。

## 2.3.3  深度相机

视觉SLAM是通过单目摄像头、双目摄像头、鱼眼摄像头、RGBD摄像头等作为传感器，将传感器数据处理后传入SLAM算法。我们常用的单目摄像头可以通过几帧图像间的信息对比得到画面内的深度信息；双目摄像头的原理与我们人眼的测距原理一致，但是不能看到黑暗处的深度信息，属于被动测量；RGBD相机能主动发射红外光，根据反射回的反射光得到深度信息，属于主动测量。所以本机器人选用RGBD相机。

本人共使用过三款不同的RGBD相机，分别为：Kinect V1、Kinect V2和Real Sense D435。

Kinect相机由微软公司生产，其中KinectV1是基于结构光原理，KinectV2是基于TOF原理。后者相较于前者有更宽阔的视场角，生成的深度图质量较高。Kinect的软件工具包里的部分工具性能较强，如人体骨架追踪，能同时进行六个人的骨架追踪。但是在本人的实际使用中，Kinect相机对Ubuntu系统兼容性较差，特别是KinectV2，在Ubuntu操作系统中需要借助OpenNI2和libfreenect2功能包，其功能有一定限制。

Real SenseD435是由英特尔公司生产的深度相机，这款相机在2018年推出，支持Windows、Linux、Mac OS等平台。与Kinect相机相比，Real Sense D435相机性能更强，配置更新。在实际使用中，Real Sense实现的功能也比较丰富，廖萱等人\[7]使用RealSense相机实现了基于RGB-D传感器的机器人视觉里程计；周雄才\[8]实现了一种基于Real Sense深度信息的障碍物检测和避障方法；W. Ma等人\[9]提出了一种基于Real Sense D435的三维物体点云快速重建方法。

综上，本机器人的深度相机使用Real Sense D435深度相机。
